{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissao zero shot\n",
    "\n",
    "## Utils de API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anthropic\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "# gemini-embedding-exp\n",
    "client_google = genai.Client(\n",
    "    api_key= os.environ.get(\"GEMINI_API_KEY\")\n",
    "    )\n",
    "\n",
    "PROVIDER_ANTHROPIC = \"anthropic\"\n",
    "PROVIDER_GOOGLE = \"google\"\n",
    "\n",
    "def classify_texts_batched(df_input, output_csv_path, batch_size=10, model=\"claude-3-7-sonnet-20250219\", provider=\"anthropic\"):\n",
    "    \n",
    "    df = df_input.copy()\n",
    "    df['Label'] = ''\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert at identifying AI-generated text versus human-written text.\n",
    "    \n",
    "    Analyze each numbered text sample carefully and classify it as either 'Human' or 'AI' based on these criteria:\n",
    "    \n",
    "    Human-written text often:\n",
    "    - Contains personal anecdotes or emotional nuance\n",
    "    - Has natural irregularities, varying sentence structures\n",
    "    - May include idioms, slang, or colloquialisms \n",
    "    - Can have slight grammatical errors or typos\n",
    "    - Often has a distinctive voice or style\n",
    "    \n",
    "    AI-generated text often:\n",
    "    - Has more uniform sentence structures\n",
    "    - Uses more formal or academic language consistently\n",
    "    - Organizes information very systematically\n",
    "    - Rarely contains spelling errors or typos\n",
    "    - May have repetitive patterns or phrasing\n",
    "    \n",
    "    IMPORTANT: Return your analysis as a CSV format with two columns (ID,LABEL) where classification is ONLY 'Human' or 'AI'.\n",
    "    Do not include any other text in your response besides the CSV data.\n",
    "    Do not add a prefix such as csv.\n",
    "    Example output format:\n",
    "    ID,LABEL\n",
    "    1,Human\n",
    "    2,AI\n",
    "    3,Human\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process dataframe in batches\n",
    "    num_samples = len(df)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size  # Ceiling division\n",
    "    \n",
    "    print(f\"Processing {num_samples} text samples in {num_batches} batches of size {batch_size}...\")\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches)):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_df = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Prepare the batch of texts to classify\n",
    "        batch_text = \"\"\n",
    "        for i, (_, row) in enumerate(batch_df.iterrows()):\n",
    "            relative_idx = i + 1\n",
    "            text = row['Text']\n",
    "            batch_text += f\"Text {relative_idx}: {text}\\n\\n\"\n",
    "        \n",
    "        # Prepare the user message\n",
    "        user_message = f\"Please classify each of the following texts as either 'Human' or 'AI':\\n\\n{batch_text}\\n\\nReturn your analysis in CSV format with columns 'ID' and 'Label'.\"\n",
    "        \n",
    "        # print(f\"Prompting the following message: {user_message}\")\n",
    "\n",
    "        max_retries = 3\n",
    "        retry_delay = 2\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "\n",
    "                if provider == PROVIDER_ANTHROPIC:\n",
    "                    response = client.messages.create(\n",
    "                        model=model,\n",
    "                        system=system_prompt,\n",
    "                        max_tokens=1000,  \n",
    "                        messages=[\n",
    "                            {\"role\": \"user\", \"content\": user_message}\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    csv_response = response.content[0].text.strip()\n",
    "                else: # google\n",
    "                    \n",
    "                    response = client_google.models.generate_content(\n",
    "                        model= model,\n",
    "                        contents= user_message,\n",
    "                        config=types.GenerateContentConfig(\n",
    "                            system_instruction = system_prompt #,\n",
    "                           # max_output_tokens=1000,\n",
    "                        )\n",
    "                    )\n",
    "                    # flash adds csv prefix.\n",
    "                    csv_response = response.text.removeprefix(\"```csv\\n\").removesuffix(\"```\").strip()\n",
    "\n",
    "                try:\n",
    "                    import io\n",
    "                    result_df = pd.read_csv(io.StringIO(csv_response))\n",
    "                    \n",
    "                    for row in  range(len(result_df)):\n",
    "                        relative_idx = result_df.iloc[row,0]\n",
    "                        classification = result_df.iloc[row,1]\n",
    "                                                \n",
    "                        classification = classification.upper()\n",
    "\n",
    "                        if classification == 'HUMAN':\n",
    "                            classification = 'Human'\n",
    "\n",
    "                        abs_idx = start_idx + relative_idx - 1\n",
    "                        \n",
    "                        if abs_idx < end_idx: \n",
    "                            df.at[abs_idx, 'Label'] = classification\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing CSV response: {e}\")\n",
    "                    print(f\"Raw response: {csv_response}\")\n",
    "\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error on attempt {attempt+1}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    df.loc[start_idx:end_idx-1, 'Label'] = 'error'\n",
    "                    print(f\"Failed to classify batch after {max_retries} attempts.\")\n",
    "        \n",
    "        # Add a small delay between batches to respect rate limits\n",
    "        time.sleep(1)\n",
    "    \n",
    "    df = df[['ID','Label']]\n",
    "    df.set_index('ID', inplace=True)\n",
    "    df.to_csv(output_csv_path, index=True, sep='\\t')\n",
    "    print(f\"Classification complete. Results saved to {output_csv_path}\")\n",
    "    \n",
    "    # Return summary statistics\n",
    "    human_count = (df['Label'] == 'Human').sum()\n",
    "    ai_count = (df['Label'] == 'AI').sum()\n",
    "    other_count = len(df) - human_count - ai_count\n",
    "    \n",
    "    print(f\"Summary:\\n- Human texts: {human_count}\\n- AI texts: {ai_count}\\n- Other/errors: {other_count}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('dataset2_disclosed_complete.csv', sep=';')\n",
    "df_test['Label'] = df_test['Label'].astype(str)\n",
    "df_test.loc[df_test['Label'] == 'Ai', 'Label'] = \"AI\"\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def test_model(y_pred):\n",
    "    y_pred = y_pred.astype(str) \n",
    "    print(classification_report(df_test['Label'], y_pred))\n",
    "    print(confusion_matrix(df_test['Label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste novos modelos da google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O gemini mais pequeno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 text samples in 10 batches of size 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. Results saved to test-flash-8b-zeroshot.csv\n",
      "Summary:\n",
      "- Human texts: 23\n",
      "- AI texts: 77\n",
      "- Other/errors: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.53      0.84      0.65        49\n",
      "       Human       0.65      0.29      0.41        51\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.59      0.57      0.53       100\n",
      "weighted avg       0.59      0.56      0.53       100\n",
      "\n",
      "[[41  8]\n",
      " [36 15]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_flash_8b = classify_texts_batched(df_test, \"test-flash-8b-zeroshot.csv\", batch_size=10,model = \"gemini-1.5-flash-8b\", provider=PROVIDER_GOOGLE)\n",
    "test_model(test_flash_8b['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O gemini flash ( modelo mais equilibrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 text samples in 10 batches of size 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. Results saved to test-flash-normal-zeroshot.csv\n",
      "Summary:\n",
      "- Human texts: 18\n",
      "- AI texts: 82\n",
      "- Other/errors: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.59      0.98      0.73        49\n",
      "       Human       0.94      0.33      0.49        51\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.76      0.66      0.61       100\n",
      "weighted avg       0.77      0.65      0.61       100\n",
      "\n",
      "[[48  1]\n",
      " [34 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_flash = classify_texts_batched(df_test, \"test-flash-normal-zeroshot.csv\", batch_size=10,model = \"gemini-2.0-flash\", provider=PROVIDER_GOOGLE)\n",
    "test_model(test_flash['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini pro 2.5, modelo para tarefas mais complexas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.55      0.98      0.70        49\n",
      "       Human       0.92      0.22      0.35        51\n",
      "\n",
      "    accuracy                           0.59       100\n",
      "   macro avg       0.73      0.60      0.52       100\n",
      "weighted avg       0.73      0.59      0.52       100\n",
      "\n",
      "[[48  1]\n",
      " [40 11]]\n"
     ]
    }
   ],
   "source": [
    "test_gemini_pro = classify_texts_batched(df_test, \"test-gemini-pro-zeroshot.csv\", batch_size=10,model = \"gemini-2.5-pro-exp-03-25\", provider=PROVIDER_GOOGLE)\n",
    "test_model(test_gemini_pro['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude sonnet, o modelo mais equilibrado. Usado na submissão anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 text samples in 10 batches of size 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. Results saved to test-claude-zeroshot.csv\n",
      "Summary:\n",
      "- Human texts: 42\n",
      "- AI texts: 58\n",
      "- Other/errors: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.81      0.96      0.88        49\n",
      "       Human       0.95      0.78      0.86        51\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.88      0.87      0.87       100\n",
      "weighted avg       0.88      0.87      0.87       100\n",
      "\n",
      "[[47  2]\n",
      " [11 40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6 cents cost\n",
    "test_claude = classify_texts_batched(df_test, \"test-claude-zeroshot.csv\", batch_size=10, model = \"claude-3-7-sonnet-20250219\", provider=PROVIDER_ANTHROPIC)\n",
    "test_model(test_claude['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo mais eficiente da anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.49      0.37      0.42        49\n",
      "       Human       0.51      0.63      0.56        51\n",
      "\n",
      "    accuracy                           0.50       100\n",
      "   macro avg       0.50      0.50      0.49       100\n",
      "weighted avg       0.50      0.50      0.49       100\n",
      "\n",
      "[[18 31]\n",
      " [19 32]]\n"
     ]
    }
   ],
   "source": [
    "test_haiku = classify_texts_batched(df_test, \"test-haiku-zeroshot.csv\", batch_size=10, model = \"claude-3-haiku-20240307\", provider=PROVIDER_ANTHROPIC)\n",
    "test_model(test_haiku['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo mais complexo da anthropic \n",
    "\n",
    "O opus foi testado anteriormente e teve resultados signficativamente piores que o claude-sonnet. Quase 30% de diferença na accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissão do melhor modelo em zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 text samples in 10 batches of size 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. Results saved to submissao3-grupo008-s1.csv\n",
      "Summary:\n",
      "- Human texts: 41\n",
      "- AI texts: 59\n",
      "- Other/errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5f760402-ac2d-4504-a884-ecf5e6dd6098",
       "rows": [
        [
         "D3-1",
         "Human"
        ],
        [
         "D3-2",
         "AI"
        ],
        [
         "D3-3",
         "AI"
        ],
        [
         "D3-4",
         "Human"
        ],
        [
         "D3-5",
         "Human"
        ],
        [
         "D3-6",
         "AI"
        ],
        [
         "D3-7",
         "Human"
        ],
        [
         "D3-8",
         "AI"
        ],
        [
         "D3-9",
         "AI"
        ],
        [
         "D3-10",
         "AI"
        ],
        [
         "D3-11",
         "Human"
        ],
        [
         "D3-12",
         "AI"
        ],
        [
         "D3-13",
         "AI"
        ],
        [
         "D3-14",
         "AI"
        ],
        [
         "D3-15",
         "Human"
        ],
        [
         "D3-16",
         "Human"
        ],
        [
         "D3-17",
         "AI"
        ],
        [
         "D3-18",
         "Human"
        ],
        [
         "D3-19",
         "Human"
        ],
        [
         "D3-20",
         "Human"
        ],
        [
         "D3-21",
         "AI"
        ],
        [
         "D3-22",
         "Human"
        ],
        [
         "D3-23",
         "AI"
        ],
        [
         "D3-24",
         "AI"
        ],
        [
         "D3-25",
         "AI"
        ],
        [
         "D3-26",
         "Human"
        ],
        [
         "D3-27",
         "Human"
        ],
        [
         "D3-28",
         "AI"
        ],
        [
         "D3-29",
         "AI"
        ],
        [
         "D3-30",
         "AI"
        ],
        [
         "D3-31",
         "AI"
        ],
        [
         "D3-32",
         "AI"
        ],
        [
         "D3-33",
         "Human"
        ],
        [
         "D3-34",
         "AI"
        ],
        [
         "D3-35",
         "Human"
        ],
        [
         "D3-36",
         "Human"
        ],
        [
         "D3-37",
         "AI"
        ],
        [
         "D3-38",
         "Human"
        ],
        [
         "D3-39",
         "Human"
        ],
        [
         "D3-40",
         "AI"
        ],
        [
         "D3-41",
         "AI"
        ],
        [
         "D3-42",
         "Human"
        ],
        [
         "D3-43",
         "AI"
        ],
        [
         "D3-44",
         "Human"
        ],
        [
         "D3-45",
         "AI"
        ],
        [
         "D3-46",
         "AI"
        ],
        [
         "D3-47",
         "Human"
        ],
        [
         "D3-48",
         "AI"
        ],
        [
         "D3-49",
         "Human"
        ],
        [
         "D3-50",
         "AI"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D3-1</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-2</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-3</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-4</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-5</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-96</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-97</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-98</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-99</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-100</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label\n",
       "ID           \n",
       "D3-1    Human\n",
       "D3-2       AI\n",
       "D3-3       AI\n",
       "D3-4    Human\n",
       "D3-5    Human\n",
       "...       ...\n",
       "D3-96      AI\n",
       "D3-97   Human\n",
       "D3-98      AI\n",
       "D3-99      AI\n",
       "D3-100  Human\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_input = pd.read_csv('submission3_inputs.csv', sep=';')\n",
    "\n",
    "classify_texts_batched(df_input, \"submissao3-grupo008-s1.csv\", batch_size=10, model = \"claude-3-7-sonnet-20250219\", provider=PROVIDER_ANTHROPIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
