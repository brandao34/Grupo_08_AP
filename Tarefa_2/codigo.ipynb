{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Pré-processamento com Pandas/Scikit-learn\n",
    "# ==============================================\n",
    "\n",
    "# Carregar e combinar datasets\n",
    "#inputs_df = pd.read_csv('Dataset6_clean_input.csv')\n",
    "#outputs_df = pd.read_csv('Dataset6_clean_output.csv')\n",
    "#df = pd.merge(inputs_df, outputs_df, on='ID')\n",
    "df = pd.read_csv('../Tarefa_1/Dataset6_clean.csv' , sep=',')\n",
    "# Vetorização do texto\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Text']).toarray()\n",
    "y = df['Label'].map({'AI':1, 'Human':0}).values\n",
    "\n",
    "# Divisão treino-teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Modelos Implementados com Numpy\n",
    "# ==============================================\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self._sigmoid(linear)\n",
    "            \n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self._sigmoid(linear)\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.01):\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        self.lr = lr\n",
    "\n",
    "    def _relu(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def _relu_deriv(self, Z):\n",
    "        return Z > 0\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self._relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        return self._sigmoid(self.z2)\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        m = y.shape[0]\n",
    "        \n",
    "        dz2 = output - y.reshape(-1,1)\n",
    "        dW2 = (1/m) * np.dot(self.a1.T, dz2)\n",
    "        db2 = (1/m) * np.sum(dz2, axis=0, keepdims=True)\n",
    "        \n",
    "        dz1 = np.dot(dz2, self.W2.T) * self._relu_deriv(self.z1)\n",
    "        dW1 = (1/m) * np.dot(X.T, dz1)\n",
    "        db1 = (1/m) * np.sum(dz1, axis=0)\n",
    "\n",
    "        return dW1, db1, dW2, db2\n",
    "\n",
    "    def train(self, X, y, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            dW1, db1, dW2, db2 = self.backward(X, y, output)\n",
    "            \n",
    "            self.W1 -= self.lr * dW1\n",
    "            self.b1 -= self.lr * db1\n",
    "            self.W2 -= self.lr * dW2\n",
    "            self.b2 -= self.lr * db2\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.forward(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "LR Test Accuracy: 0.96\n",
      "\n",
      "Training Neural Network...\n",
      "NN Test Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Treino e Avaliação\n",
    "# ==============================================\n",
    "\n",
    "# Treinar Regressão Logística\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr = LogisticRegression(lr=0.1, n_iters=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_acc = np.mean(lr.predict(X_test) == y_test)\n",
    "print(f\"LR Test Accuracy: {lr_acc:.2f}\")\n",
    "\n",
    "# Treinar Rede Neural\n",
    "print(\"\\nTraining Neural Network...\")\n",
    "nn = NeuralNetwork(input_size=X_train.shape[1], hidden_size=64, \n",
    "                   output_size=1, lr=0.01)\n",
    "nn.train(X_train, y_train, epochs=1000)\n",
    "nn_acc = np.mean(nn.predict(X_test) == y_test)\n",
    "print(f\"NN Test Accuracy: {nn_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
