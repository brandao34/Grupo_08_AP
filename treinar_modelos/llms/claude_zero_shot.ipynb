{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(citations=None, text=\"Hello! It's nice to meet you. How can I help you today? I'm ready to assist with information, answer questions, or have a conversation about whatever's on your mind.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "# pip install anthropic\n",
    "import anthropic\n",
    "\n",
    "# export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    # api_key=key,\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
    "    ]\n",
    ")\n",
    "print(message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anthropic\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "def classify_texts_batched(df, output_csv_path, batch_size=10, model=\"claude-3-7-sonnet-20250219\"):\n",
    "    \n",
    "    df['Label'] = ''\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert at identifying AI-generated text versus human-written text.\n",
    "    \n",
    "    Analyze each numbered text sample carefully and classify it as either 'Human' or 'AI' based on these criteria:\n",
    "    \n",
    "    Human-written text often:\n",
    "    - Contains personal anecdotes or emotional nuance\n",
    "    - Has natural irregularities, varying sentence structures\n",
    "    - May include idioms, slang, or colloquialisms \n",
    "    - Can have slight grammatical errors or typos\n",
    "    - Often has a distinctive voice or style\n",
    "    \n",
    "    AI-generated text often:\n",
    "    - Has more uniform sentence structures\n",
    "    - Uses more formal or academic language consistently\n",
    "    - Organizes information very systematically\n",
    "    - Rarely contains spelling errors or typos\n",
    "    - May have repetitive patterns or phrasing\n",
    "    \n",
    "    IMPORTANT: Return your analysis as a CSV format with two columns (ID,LABEL) where classification is ONLY 'Human' or 'AI'.\n",
    "    Do not include any other text in your response besides the CSV data.\n",
    "    Example output format:\n",
    "    ID,LABEL\n",
    "    1,human\n",
    "    2,AI\n",
    "    3,human\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process dataframe in batches\n",
    "    num_samples = len(df)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size  # Ceiling division\n",
    "    \n",
    "    print(f\"Processing {num_samples} text samples in {num_batches} batches of size {batch_size}...\")\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches)):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_df = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "\n",
    "        # Prepare the batch of texts to classify\n",
    "        batch_text = \"\"\n",
    "        for i, (_, row) in enumerate(batch_df.iterrows()):\n",
    "            relative_idx = i + 1\n",
    "            text = row['Text']\n",
    "            batch_text += f\"Text {relative_idx}: {text}\\n\\n\"\n",
    "        \n",
    "        # Prepare the user message\n",
    "        user_message = f\"Please classify each of the following texts as either 'Human' or 'AI':\\n\\n{batch_text}\\n\\nReturn your analysis in CSV format with columns 'ID' and 'Label'.\"\n",
    "        \n",
    "        # print(f\"Prompting the following message: {user_message}\")\n",
    "\n",
    "        max_retries = 3\n",
    "        retry_delay = 2\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.messages.create(\n",
    "                    model=model,\n",
    "                    system=system_prompt,\n",
    "                    max_tokens=100,  \n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": user_message}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                csv_response = response.content[0].text.strip()\n",
    "                \n",
    "                # Parse the CSV response\n",
    "                try:\n",
    "                    import io\n",
    "                    result_df = pd.read_csv(io.StringIO(csv_response))\n",
    "                    \n",
    "                    for row in  range(len(result_df)):\n",
    "                        relative_idx = result_df.iloc[row,0]\n",
    "                        classification = result_df.iloc[row,1]\n",
    "                                                \n",
    "                        abs_idx = start_idx + relative_idx - 1\n",
    "                        \n",
    "                        if abs_idx < end_idx: \n",
    "                            df.at[abs_idx, 'Label'] = classification\n",
    "\n",
    "                    \n",
    "                    print(f\"Processed sucessfully batch {batch_idx}\")\n",
    "\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing CSV response: {e}\")\n",
    "                    print(f\"Raw response: {csv_response}\")\n",
    "\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error on attempt {attempt+1}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    df.loc[start_idx:end_idx-1, 'Label'] = 'error'\n",
    "                    print(f\"Failed to classify batch after {max_retries} attempts.\")\n",
    "        \n",
    "        # Add a small delay between batches to respect rate limits\n",
    "        time.sleep(5)\n",
    "    \n",
    "    df = df.drop(['Text'], axis=1)\n",
    "    df.set_index('ID', inplace=True)\n",
    "    df.to_csv(output_csv_path, index=True, sep='\\t')\n",
    "    print(f\"Classification complete. Results saved to {output_csv_path}\")\n",
    "    \n",
    "    # Return summary statistics\n",
    "    human_count = (df['Label'] == 'Human').sum()\n",
    "    ai_count = (df['Label'] == 'AI').sum()\n",
    "    other_count = len(df) - human_count - ai_count\n",
    "    \n",
    "    print(f\"Summary:\\n- Human texts: {human_count}\\n- AI texts: {ai_count}\\n- Other/errors: {other_count}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 text samples in 3 batches of size 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:07<00:15,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:14<00:07,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:21<00:00,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. Results saved to test.csv\n",
      "Summary:\n",
      "- Human texts: 14\n",
      "- AI texts: 16\n",
      "- Other/errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b2ba6b2f-584d-40af-9423-b5d7c7cfb5db",
       "rows": [
        [
         "D1-1",
         "Human"
        ],
        [
         "D1-2",
         "AI"
        ],
        [
         "D1-3",
         "Human"
        ],
        [
         "D1-4",
         "AI"
        ],
        [
         "D1-5",
         "Human"
        ],
        [
         "D1-6",
         "AI"
        ],
        [
         "D1-7",
         "Human"
        ],
        [
         "D1-8",
         "AI"
        ],
        [
         "D1-9",
         "Human"
        ],
        [
         "D1-10",
         "AI"
        ],
        [
         "D1-11",
         "Human"
        ],
        [
         "D1-12",
         "AI"
        ],
        [
         "D1-13",
         "Human"
        ],
        [
         "D1-14",
         "AI"
        ],
        [
         "D1-15",
         "Human"
        ],
        [
         "D1-16",
         "AI"
        ],
        [
         "D1-17",
         "AI"
        ],
        [
         "D1-18",
         "AI"
        ],
        [
         "D1-19",
         "Human"
        ],
        [
         "D1-20",
         "AI"
        ],
        [
         "D1-21",
         "Human"
        ],
        [
         "D1-22",
         "AI"
        ],
        [
         "D1-23",
         "Human"
        ],
        [
         "D1-24",
         "AI"
        ],
        [
         "D1-25",
         "Human"
        ],
        [
         "D1-26",
         "AI"
        ],
        [
         "D1-27",
         "Human"
        ],
        [
         "D1-28",
         "AI"
        ],
        [
         "D1-29",
         "Human"
        ],
        [
         "D1-30",
         "AI"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1-1</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-2</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-3</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-4</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-5</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-6</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-7</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-8</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-9</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-10</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-11</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-12</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-13</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-14</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-15</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-16</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-17</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-18</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-19</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-20</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-21</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-22</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-23</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-24</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-25</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-26</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-27</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-28</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-29</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1-30</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "ID          \n",
       "D1-1   Human\n",
       "D1-2      AI\n",
       "D1-3   Human\n",
       "D1-4      AI\n",
       "D1-5   Human\n",
       "D1-6      AI\n",
       "D1-7   Human\n",
       "D1-8      AI\n",
       "D1-9   Human\n",
       "D1-10     AI\n",
       "D1-11  Human\n",
       "D1-12     AI\n",
       "D1-13  Human\n",
       "D1-14     AI\n",
       "D1-15  Human\n",
       "D1-16     AI\n",
       "D1-17     AI\n",
       "D1-18     AI\n",
       "D1-19  Human\n",
       "D1-20     AI\n",
       "D1-21  Human\n",
       "D1-22     AI\n",
       "D1-23  Human\n",
       "D1-24     AI\n",
       "D1-25  Human\n",
       "D1-26     AI\n",
       "D1-27  Human\n",
       "D1-28     AI\n",
       "D1-29  Human\n",
       "D1-30     AI"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# classify_texts_batched(\"../../Submissao2/dataset3_inputs.csv\", output_file, batch_size=25)\n",
    "\n",
    "df_input = pd.read_csv('../../datasets/val/dataset1_inputs.csv', sep='\\t')\n",
    "\n",
    "# Opus teve piores resultados. 63% accuracy e custou 10centimos! sonnet custa 1-2cents e tem cerca de 95% accuracy\n",
    "# classify_texts_batched(df_input, \"test.csv\", batch_size=10, model= 'claude-3-opus-latest')\n",
    "\n",
    "classify_texts_batched(df_input, \"test.csv\", batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.94      1.00      0.97        15\n",
      "       Human       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "[[15  0]\n",
      " [ 1 14]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "df_input = pd.read_csv('../../datasets/val/dataset1_inputs.csv', sep='\\t')\n",
    "df_output = pd.read_csv('../../datasets/val/dataset1_outputs.csv', sep='\\t')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def test_model(y_pred):\n",
    "    y_test = df_output['Label']\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "test = pd.read_csv(\"test.csv\",sep=\"\\t\")\n",
    "test_model(test[\"Label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
