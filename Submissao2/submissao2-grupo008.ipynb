{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissao zero shot claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anthropic\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "def classify_texts_batched(df, output_csv_path, batch_size=10, model=\"claude-3-7-sonnet-20250219\"):\n",
    "    \n",
    "    df['Label'] = ''\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert at identifying AI-generated text versus human-written text.\n",
    "    \n",
    "    Analyze each numbered text sample carefully and classify it as either 'Human' or 'AI' based on these criteria:\n",
    "    \n",
    "    Human-written text often:\n",
    "    - Contains personal anecdotes or emotional nuance\n",
    "    - Has natural irregularities, varying sentence structures\n",
    "    - May include idioms, slang, or colloquialisms \n",
    "    - Can have slight grammatical errors or typos\n",
    "    - Often has a distinctive voice or style\n",
    "    \n",
    "    AI-generated text often:\n",
    "    - Has more uniform sentence structures\n",
    "    - Uses more formal or academic language consistently\n",
    "    - Organizes information very systematically\n",
    "    - Rarely contains spelling errors or typos\n",
    "    - May have repetitive patterns or phrasing\n",
    "    \n",
    "    IMPORTANT: Return your analysis as a CSV format with two columns (ID,LABEL) where classification is ONLY 'Human' or 'AI'.\n",
    "    Do not include any other text in your response besides the CSV data.\n",
    "    Example output format:\n",
    "    ID,LABEL\n",
    "    1,human\n",
    "    2,AI\n",
    "    3,human\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process dataframe in batches\n",
    "    num_samples = len(df)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size  # Ceiling division\n",
    "    \n",
    "    print(f\"Processing {num_samples} text samples in {num_batches} batches of size {batch_size}...\")\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches)):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_df = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "\n",
    "        # Prepare the batch of texts to classify\n",
    "        batch_text = \"\"\n",
    "        for i, (_, row) in enumerate(batch_df.iterrows()):\n",
    "            relative_idx = i + 1\n",
    "            text = row['Text']\n",
    "            batch_text += f\"Text {relative_idx}: {text}\\n\\n\"\n",
    "        \n",
    "        # Prepare the user message\n",
    "        user_message = f\"Please classify each of the following texts as either 'Human' or 'AI':\\n\\n{batch_text}\\n\\nReturn your analysis in CSV format with columns 'ID' and 'Label'.\"\n",
    "        \n",
    "        # print(f\"Prompting the following message: {user_message}\")\n",
    "\n",
    "        max_retries = 3\n",
    "        retry_delay = 2\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.messages.create(\n",
    "                    model=model,\n",
    "                    system=system_prompt,\n",
    "                    max_tokens=100,  \n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": user_message}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                csv_response = response.content[0].text.strip()\n",
    "                \n",
    "                # Parse the CSV response\n",
    "                try:\n",
    "                    import io\n",
    "                    result_df = pd.read_csv(io.StringIO(csv_response))\n",
    "                    \n",
    "                    for row in  range(len(result_df)):\n",
    "                        relative_idx = result_df.iloc[row,0]\n",
    "                        classification = result_df.iloc[row,1]\n",
    "                                                \n",
    "                        abs_idx = start_idx + relative_idx - 1\n",
    "                        \n",
    "                        if abs_idx < end_idx: \n",
    "                            df.at[abs_idx, 'Label'] = classification\n",
    "\n",
    "                    \n",
    "                    print(f\"Processed sucessfully batch {batch_idx}\")\n",
    "\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing CSV response: {e}\")\n",
    "                    print(f\"Raw response: {csv_response}\")\n",
    "\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error on attempt {attempt+1}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    retry_delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    df.loc[start_idx:end_idx-1, 'Label'] = 'error'\n",
    "                    print(f\"Failed to classify batch after {max_retries} attempts.\")\n",
    "        \n",
    "        # Add a small delay between batches to respect rate limits\n",
    "        time.sleep(5)\n",
    "    \n",
    "    df = df.drop(['Text'], axis=1)\n",
    "    df.set_index('ID', inplace=True)\n",
    "    df.to_csv(output_csv_path, index=True, sep='\\t')\n",
    "    print(f\"Classification complete. Results saved to {output_csv_path}\")\n",
    "    \n",
    "    # Return summary statistics\n",
    "    human_count = (df['Label'] == 'Human').sum()\n",
    "    ai_count = (df['Label'] == 'AI').sum()\n",
    "    other_count = len(df) - human_count - ai_count\n",
    "    \n",
    "    print(f\"Summary:\\n- Human texts: {human_count}\\n- AI texts: {ai_count}\\n- Other/errors: {other_count}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 text samples in 10 batches of size 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<01:00,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:13<00:53,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:20<00:47,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:26<00:38,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:33<00:32,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:39<00:26,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:46<00:19,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:53<00:13,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:59<00:06,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sucessfully batch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:06<00:00,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. Results saved to submissao1-grupo008-s1.csv\n",
      "Summary:\n",
      "- Human texts: 39\n",
      "- AI texts: 61\n",
      "- Other/errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f6d3f42a-55f8-4f71-86c4-1c02ce54a6ab",
       "rows": [
        [
         "D3-1",
         "AI"
        ],
        [
         "D3-2",
         "AI"
        ],
        [
         "D3-3",
         "AI"
        ],
        [
         "D3-4",
         "Human"
        ],
        [
         "D3-5",
         "Human"
        ],
        [
         "D3-6",
         "AI"
        ],
        [
         "D3-7",
         "AI"
        ],
        [
         "D3-8",
         "AI"
        ],
        [
         "D3-9",
         "AI"
        ],
        [
         "D3-10",
         "AI"
        ],
        [
         "D3-11",
         "Human"
        ],
        [
         "D3-12",
         "Human"
        ],
        [
         "D3-13",
         "AI"
        ],
        [
         "D3-14",
         "AI"
        ],
        [
         "D3-15",
         "Human"
        ],
        [
         "D3-16",
         "Human"
        ],
        [
         "D3-17",
         "AI"
        ],
        [
         "D3-18",
         "Human"
        ],
        [
         "D3-19",
         "Human"
        ],
        [
         "D3-20",
         "Human"
        ],
        [
         "D3-21",
         "AI"
        ],
        [
         "D3-22",
         "Human"
        ],
        [
         "D3-23",
         "AI"
        ],
        [
         "D3-24",
         "AI"
        ],
        [
         "D3-25",
         "AI"
        ],
        [
         "D3-26",
         "Human"
        ],
        [
         "D3-27",
         "Human"
        ],
        [
         "D3-28",
         "AI"
        ],
        [
         "D3-29",
         "AI"
        ],
        [
         "D3-30",
         "AI"
        ],
        [
         "D3-31",
         "AI"
        ],
        [
         "D3-32",
         "AI"
        ],
        [
         "D3-33",
         "Human"
        ],
        [
         "D3-34",
         "AI"
        ],
        [
         "D3-35",
         "Human"
        ],
        [
         "D3-36",
         "Human"
        ],
        [
         "D3-37",
         "AI"
        ],
        [
         "D3-38",
         "Human"
        ],
        [
         "D3-39",
         "Human"
        ],
        [
         "D3-40",
         "AI"
        ],
        [
         "D3-41",
         "AI"
        ],
        [
         "D3-42",
         "Human"
        ],
        [
         "D3-43",
         "AI"
        ],
        [
         "D3-44",
         "Human"
        ],
        [
         "D3-45",
         "AI"
        ],
        [
         "D3-46",
         "AI"
        ],
        [
         "D3-47",
         "Human"
        ],
        [
         "D3-48",
         "AI"
        ],
        [
         "D3-49",
         "Human"
        ],
        [
         "D3-50",
         "AI"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D3-1</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-2</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-3</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-4</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3-5</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2-94</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2-96</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2-97</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2-98</th>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2-99</th>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "ID          \n",
       "D3-1      AI\n",
       "D3-2      AI\n",
       "D3-3      AI\n",
       "D3-4   Human\n",
       "D3-5   Human\n",
       "...      ...\n",
       "D2-94     AI\n",
       "D2-96  Human\n",
       "D2-97     AI\n",
       "D2-98  Human\n",
       "D2-99     AI\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_input = pd.read_csv('dataset3_inputs.csv', sep=';')\n",
    "\n",
    "classify_texts_batched(df_input, \"submissao2-grupo008-s1.csv\", batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
